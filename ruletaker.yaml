seed_everything: 71
optimizer:
  class_path: transformers.optimization.AdamW
  init_args:
    lr: 1e-5
    betas: [0.9, 0.98]
    weight_decay: 0.1
lr_scheduler:
# https://gist.github.com/ceshine/ff32968bafc6fead87d7b6233ad8ab69
  class_path: torch.optim.lr_scheduler.OneCycleLR
  init_args:
    epochs: 4 
    steps_per_epoch: 5004
    pct_start: 0.06
    anneal_strategy: linear
    max_lr: 1e-5
    div_factor: 32
    cycle_momentum: False
trainer:
  gpus: [6, 7]
  max_epochs: 4
  gradient_clip_val: 1.0
  # logger: 
  #   -class_path: pytorch_lightning.loggers.pl_loggers.TensorBoardLogger
  #   init_args:
  #     save_dir: logs/
  # callbacks:
  # - class_path: pytorch_lightning.callbacks.EarlyStopping
  #   init_args:
  #     monitor: val_loss
  #     patience: 2
model:
  n_classes: 2
  n_warmup_steps: 2500
  n_training_steps: 70108
  plm: roberta-large
data:
  batch_size: 8
  train_path: ../../raw_data/rule-reasoning-dataset-V2020.2.5.0/original/depth-3/train.jsonl
  dev_path: ../../raw_data/rule-reasoning-dataset-V2020.2.5.0/original/depth-3/dev.jsonl
  test_path: ../../raw_data/rule-reasoning-dataset-V2020.2.5.0/original/depth-3/test.jsonl